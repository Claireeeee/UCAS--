直接调用hanlp的word2vec包的public float similarity(String docA, String docB)，计算两个字符串的语义相似度，取得分最高的返回



15000个条目，不能全匹配

- 先筛选：选出候选集合做相似度计算——关键词匹配？
- 语料处理：先把全部的问句做分词并转化为向量？













贪心研究

- 问答库引用？





向量化：把语料库的问题和用户所提问题预处理，然后向量化，

相似度：最后通过计算两向量之间的余弦夹角值作为衡量相似度的值。

阈值：只有该余弦值大于程序设定中的阈值才会将这些问题作为候选问题返回给用户。

- 本设计的阈值设置为0.5，

返回：同时并选择相似度最高的前5个问题（Top5）所对应的答案返回给用户。

- 若没有大于阈值的样本，则提示用户当前的提问没有相似的答案







预处理：问题们

- 中文分词

  使用计算机自动地对中文文本进行词语切分的过程称为中文分词(Chinese Word Segmentation)，即使中文句子中的词之间有空格标识。若要对一个句子进行分析，就需要将其切分成词的序列，然后以词为单位进行句子的分析

- 词性标注：分词之后需要对每个词进行词性标注

- 停用词过滤：

  - 本文使用中科院的“计算所汉语词性标记集”以及哈工大停用词表对评论文本进行停用词过滤。根据“计算所汉语词性标记集”，确定出要过滤掉的词性有：标点符号、介词和代词等
  - 这些词性的词信息量低，无类别区分作用。
  - 本文先对评论文本进行词性过滤，再根据哈工大停用词表进一步过滤

——由问句得到词序列

向量化：















- 问句：语料库+用户输入

  - 向量化：使用了TF-IDF和word2vec两种方法

  - 计算相似度：先倒排列表技术筛选——再余弦

    - 倒排列表：系统在根据用户问题建立候选问题集的基础上，建立常问问题集的倒排索引，提高了系统的检索效率

    - 余弦：基于语义（而不是关键词）的方法计算相似度

      阈值：余弦值大于程序设定中的阈值才会加入候选

      返回答案：匹配问句对应的答案



文本处理：









## 要求

输入问题，给出答案

信息：

标注好的问答对

- 问题类型（5w），语义类型（fact，opinion）

知识图谱



输入、输出及要求:

1. 输入输出分别以json格式 {“answer”: “...”, “question”: “...”} 

- 例如:{“question”:“2022年冬奥会举办地是哪里”, “answer”:“北京”} 。

2. 单次响应时间在500ms以内(除去初始加载模型的时间)。
3. 最终成绩评测:测试语料上返回正确答案的可接受率(人工评测，在12月初 

提供统一的评测集)。 







自己写一个c或python程序，通过处理输入，查询指定文件夹下的文件，找到结果，输出到终端/或文件

- IO处理——QA解析/生成，语库引入
- 核心算法——文本匹配

## 开源借鉴

AnyQ：算法借鉴？or 直接引用？

- 问题分析，检索，匹配，打分——每个阶段都是实现

贪心学院

- 流程实现也可以借鉴，应该比较简单



——他们处理的都是json对，要先把excel转为json对吧？



theSimarityQASystem

- 项目总结



class guy

- 项目总结



ysc QA

- 源码，有json处理，可借鉴



段落抽取QA

- IO处理可参考







































回到技术层面，Watson所用到的知识库是一个广义的知识库，不仅包含各种结构化知识、也包含各种文本语料和语言学知识。整个流程称为Deep QA，包含问题分解、假设生成、基于证据的融合排序等关键步骤。这里的Deep QA并非指通过深度学习（Deep Learning）技术来提供问答。事实上，Watson诞生于深度学习大热之前，这里的Deep是指通过深度解析（Deep Parsing）来实现对问句的真正理解。





